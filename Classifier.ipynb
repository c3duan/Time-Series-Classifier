{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from Model import RNN, CNN\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DATA_DIR = os.path.abspath(os.path.abspath('') + '/Aniyama_groundtruth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = [p for p in os.listdir(EVAL_DATA_DIR) if not p.startswith('.')]\n",
    "dataset = []\n",
    "for t in data_types:\n",
    "    type_dir = f'{EVAL_DATA_DIR}/{t}'\n",
    "    for file in os.listdir(type_dir):\n",
    "        filename = f'{type_dir}/{file}'\n",
    "        examples = []\n",
    "        with open(filename, 'r') as f:\n",
    "            for i, line in enumerate(f.readlines()):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                tokens = line.rstrip().split(',')\n",
    "                power, anomaly = float(tokens[1]), int(tokens[2])\n",
    "                example = [power, anomaly]\n",
    "                examples.append(example)\n",
    "    examples = np.array(examples)\n",
    "    dataset.append(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "for chunk in dataset:\n",
    "    size = chunk.shape[0]\n",
    "    new_size = (math.ceil(size / 10) * 10)\n",
    "    pad_size = new_size - size\n",
    "    padding = np.zeros((pad_size, 2))\n",
    "    new_chunk = np.vstack((chunk, padding)).reshape(new_size // 10, 10, 2)\n",
    "    for i in range(new_chunk.shape[0]):\n",
    "        data.append(new_chunk[i,:,0])\n",
    "        label = new_chunk[i,:,1].sum() > 0\n",
    "        labels.append(float(label))\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3429, 10), (3429,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1698.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_text = train_test_split(data, labels, test_size = 0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "X_train, X_valid, X_test = torch.FloatTensor(X_train), torch.FloatTensor(X_train), torch.FloatTensor(X_train)\n",
    "y_train, y_valid, y_test = torch.FloatTensor(y_train), torch.FloatTensor(y_train), torch.FloatTensor(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, data, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.data = data\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.data)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        return self.data[index], self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 32,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 6,\n",
    "    'drop_last': True,\n",
    "    'num_epochs': 400,\n",
    "    'encode_dim': 1,\n",
    "    'hidden_dim': 64,\n",
    "    'output_dim': 1,\n",
    "    'num_layers': 3,\n",
    "    'dropout': 0.3,\n",
    "    'device': device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Dataset(X_train, y_train)\n",
    "train_loader = data.DataLoader(\n",
    "    train_set,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=config['shuffle'],\n",
    "    num_workers=config['num_workers'],\n",
    "    drop_last=config['drop_last']\n",
    ")\n",
    "\n",
    "validation_set = Dataset(X_valid, y_valid)\n",
    "validation_loader = data.DataLoader(\n",
    "    validation_set,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=config['shuffle'],\n",
    "    num_workers=config['num_workers'],\n",
    "    drop_last=config['drop_last']\n",
    ")\n",
    "\n",
    "test_set = Dataset(X_test, y_test)\n",
    "test_loader = data.DataLoader(\n",
    "    test_set,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=config['shuffle'],\n",
    "    num_workers=config['num_workers'],\n",
    "    drop_last=config['drop_last']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "models['baseline_rnn'] = RNN(\n",
    "    config['encode_dim'],\n",
    "    config['hidden_dim'],\n",
    "    config['output_dim'],\n",
    "    config['num_layers'],\n",
    "    config['dropout']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models['baseline_rnn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorBoard Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/baseline_rnn/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 83,777 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(config['device'])\n",
    "criterion = criterion.to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_data, batch_labels in loader:\n",
    "        \n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch_data).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, batch_labels)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch_labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_data, batch_labels in loader:\n",
    "            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "            \n",
    "            predictions = model(batch_data).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch_labels)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch_labels)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(loader), epoch_acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, loader, device):\n",
    "    epoch_acc = 0\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_data, batch_labels in loader:\n",
    "            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "            \n",
    "            predictions = model(batch_data).squeeze(1)\n",
    "            acc = binary_accuracy(predictions, batch_labels)\n",
    "\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_acc / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1209480d6a2c45e8bbfc302040316abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm_notebook(range(config['num_epochs'])):\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, config['device'])\n",
    "    valid_loss, valid_acc = evaluate(model, validation_loader, criterion, config['device'])\n",
    "    \n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'rnn-base-model.pt')\n",
    "    \n",
    "    # log the running loss\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/validation', valid_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    writer.add_scalar('Accuracy/validation', valid_acc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89111328125"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_loader, config['device'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/baseline_cnn/')\n",
    "models['baseline_cnn'] = CNN()\n",
    "model = models['baseline_cnn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,074 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(config['device'])\n",
    "criterion = criterion.to(config['device'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "594b432c6c4c452c9d36f3afb65b0cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=400), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in tqdm_notebook(range(config['num_epochs'])):\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_loader, optimizer, criterion, config['device'])\n",
    "    valid_loss, valid_acc = evaluate(model, validation_loader, criterion, config['device'])\n",
    "    \n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'cnn-base-model.pt')\n",
    "    \n",
    "    # log the running loss\n",
    "    writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "    writer.add_scalar('Loss/validation', valid_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', train_acc, epoch)\n",
    "    writer.add_scalar('Accuracy/validation', valid_acc, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87841796875"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model, test_loader, config['device'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
